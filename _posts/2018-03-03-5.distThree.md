---
title: 4. Various probability distribution III
category: Mathematical Statistics
tag: Mathematical Statistics
---

이 내용은 **수리통계학, 김우철, 민영사, 2012** 을 기반으로 합니다.

## 정규분포(Normal distribution)

<center><a href="https://imgur.com/Efn4bMx"><img src="https://i.imgur.com/Efn4bMx.png" width="400px" height="400px" title="source: imgur.com" /></a></center>

이항분포의 누적 확률을 적분으로 근사하는 근사식

>$\sum_{a \leq x \leq b}\binom{n}{x}p^{x}(1-p)^{n-x} \sum \int_{a}^{b}\frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}z^{2}} dz, n \to \infty$

에서 함수 $\phi(z)=\frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}z^{2}}, -\infty < z < \infty$는 적분 값이 1이 되는 함수로서 표준정규분포의 확률밀도함수라고 한다. 일반적으로 함수

>$\frac{1}{\sigma}\phi(\frac{x-\mu}{\sigma})=\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{1}{2}\frac{(x-\mu)^{2}}{\sigma^{2}}}, -\infty < x < \infty; \sigma > 0$

를 정규분포의 확률밀도함수라고 하고 $X \sim N(\mu, \sigma^{2})$으로 표기한다.

**성질**

1. $X \sim N(\mu, \sigma^{2})$이면
> $E(X) = \mu, Var(X)=\sigma^{2}$

2. $X \sim N(\mu, \sigma^{2})$이면 그 적률생성함수는
> $mgf_{X}(t)=e^{\mu t + \frac{1}{2}\sigma^{2}t^{2}}, -\infty < t < \infty$

3. $X_{1} \sim N(\mu_{1}, \sigma_{1}^{2}), X_{2} \sim N(\mu_{2}, \sigma_{2}^{2})$이고 $X_{1}, X_{2}$가 서로 독립이면
> $X_{1}+X_{2} \sim N(\mu_{1}+\mu_{2}, \sigma_{1}^{2}+\sigma_{2}^{2})$

4. $X \sim N(\mu, \sigma^{2})$이면 상수 $a, b$에 대하여
> $aX+b \sim N(a\mu+b, a^{2}\sigma^{2})$

## 로그정규분포(Log-normal distribution)

<center><a href="https://imgur.com/72ilYT0"><img src="https://i.imgur.com/72ilYT0.png" width="400px" height="400px" title="source: imgur.com" /></a></center>

만약 $\log(X) \sim N(\mu, \sigma^{2}), x > 0$이라면 $X$는 로그정규분포를 따른다고 하고 $X \sim Lognormal(\mu, \sigma^{2}), x > 0$와 같이 표기한다. $Z \sim N(0,1)$일 때 $X=e^{\mu+\sigma Z}$로 표현할 수 있다. 사실 이러한 관계는 밑이 $e$가 아니여도 성립한다. $\log(X) \sim N(\mu, \sigma^{2}), x > 0$일 때 $\Phi$를 정규분포의 누적확률분포라고 하면:

$$
\begin{align*}
  f(x) &= \frac{d}{dx}P(X \leq x) = \frac{d}{dx}P(\log X \leq \log x) \\
  &= \frac{d}{dx} \Phi(\frac{\log x - \mu}{\sigma}) \\
  &= \phi(\frac{\log x - \mu}{\sigma}) \frac{d}{dx} (\frac{\log x - \mu}{\sigma})\\
  &= \phi(\frac{\log x - \mu}{\sigma}) \frac{1}{\sigma x} \\
  &= \frac{1}{x} \frac{1}{\sigma \sqrt{2\pi}} \exp(-\frac{(\log x - \mu)^{2}}{2\sigma^{2}})
\end{align*}
$$

**성질**

1. $ E(X)=e^{\mu+\frac{1}{2}\sigma^{2}}, Var(X)=e^{2\mu+\sigma^{2}}(e^{\sigma^{2}}-1)$

2. $X \sim N(\mu, \sigma^{2})$이라면 $exp(X) \sim Lognormal(\mu, \sigma^{2})$

3. $X_{j} \sim Lognormal(\mu_{j}, \sigma_{j}^{2})$이고 $Y=\prod_{j=1}^{n} X_{j}$이라면 $Y \sim Lognormal(\sum_{j=1}^{n} \mu_{j}, \sum_{j=1}^{n}\sigma_{j}^{2})$

4. $X \sim Lognormal(\mu, \sigma^{2})$에서 확률변수 $X$에 대한 더하기 혹은 곱하기 등은 $X$에 로그를 취하면 결과를 알기 쉽다. 예컨대 $\frac{1}{X} \sim Lognormal(-\mu, \sigma^{2}), aX \sim Lognormal(\mu+\log a, \sigma^{2}), X^{a} \sim Lognormal(a\mu, a^{2}\sigma^{2}) $

**증명(1 유도)**

$X \sim Lognormal(\mu, \sigma^{2})$이라면 $X=e^{\mu + \sigma Z}$라고 할 수 있다. 그렇다면

> $E(X^{n})=E(e^{n\mu + n\sigma Z})=e^{n \mu} \times mgf_{Z}(n\sigma)$

한편 $mgf_{Z}=e^{\frac{1}{2}t^{2}}$이므로 $E(X^{n})=e^{n\mu+\frac{1}{2}n^{2}\sigma^{2}}$이고 이에 따라 $E(X)=e^{\mu + \frac{1}{2}\sigma^{2}}, E(X^{2})=e^{2\mu+2\sigma^{2}}$

**활용**

실생활에는 $Lognormal$분포를 따른다고 알려진 일들이 많다.

- 인터넷 토론 답변의 길이 분포
- 경제학에서 97%-99% 인구의 소득 분포
- 도시 사이즈의 증가 분포
- 금융권에서의 Black-Scholes model에서는 환율, 주가를 $Lognormal$분포로 가정한다.

## t 분포(Student's t distribution)

<center><a href="https://imgur.com/tiTGkF3"><img src="https://i.imgur.com/tiTGkF3.png" width="400px" height="400px" title="source: imgur.com" /></a></center>


$X_{1},...,X_{n} \sim N(\mu, \sigma^{2})$일 때, 표본평균, 표본분산은 각각 $\bar{X}=\frac{1}{n}\sum_{i=1}^{n}X_{i}, S^{2}=\frac{1}{n-1}\sum_{i=1}^{n}(X_{i}-\bar{X})^{2}$으로 구해지고

> $\frac{\bar{X}-\mu}{\sigma/\sqrt{n}} \sim N(0,1), \frac{\bar{X}-\mu}{\sigma/\sqrt{n}} \sim t_{(n-1)}$

이다. 즉, 후자는 자유도가 $n-1$인 $t$분포를 따른다. $X$가 자유도가 $\nu$인 $t$분포를 따른다고 할 때 그에 따른 확률밀도함수는:

>$f(t)=\frac{\Gamma(\frac{\nu+1}{2})}{\sqrt{\nu\pi}\Gamma(\frac{\nu}{2})}\Big(1+\frac{t^{2}}{\nu}\Big)^{-\frac{\nu+1}{2}}$

이고, $X \sim t(\nu)$로 표기한다.

**성질**

1. $X \sim t(\nu)$이면 다음과 같다. 분산은 해당 범위에서만 다음 값을 가진다.
>$ E(X)=0; \frac{\nu}{\nu-2}, \ \nu>2 $

2. $X \sim t(\nu)$이면 $\nu=1,\nu=\infty$일 때 특정조건의 다른 확률밀도함수와 같아진다.
>$f(t)=\frac{1}{\pi(1+t^{2})}, \nu=1; \ \ f(t)=\frac{1}{\sqrt{2\pi}}e^{-\frac{t^{2}}{2}}, \nu=\infty$

즉, $t(1) \overset{d}{\equiv} Cauchy(0,1)$ 그리고 $t(\infty) \overset{d}{\equiv} N(0,1)$

3. $Z \sim N(0,1), V \sim \chi^{2}(\nu)$이고 $Z, V$가 독립일때
>$ T=\frac{Z}{\sqrt{V/\nu}}=Z\sqrt{\frac{\nu}{V}} \sim t(\nu) $

한편, 상수 $\mu$에 대해서 $(Z+\mu)\sqrt{\frac{\nu}{V}}$는 중심점이 0이 아닌 $\mu$인 *noncentral t분포* 를 따른다.

**증명(3번)**

$X_{1},...,X_{n} \overset{i.i.d.}{\sim} N(\mu, \sigma^{2})$라고 할 때, 표본평균과 표본분산은:
>$\bar{X}=\frac{1}{n}(X_{1}+\cdots+X_{n}), S^{2}=\frac{1}{n-1}\sum_{i=1}^{n}(X_{i}-\bar{X}_{n})^{2}$

그리고 **Cochran's theorem** 에 의해 확률변수 $V=(n-1)\frac{S^{2}}{\sigma^{2}} \sim \chi^{2}(n-1)$ 이다. 또한 $Z=\frac{\bar{X}-\mu}{\sigma/\sqrt{n}} \sim N(0,1)$ 이를 통해 계산하면

> $T \equiv \frac{Z}{\sqrt{V/\nu}} = \frac{\bar{X}=\mu}{S/\sqrt{n}} \sim t(n-1)$

## 코시분포(Cauchy distribution)

<center><a href="https://imgur.com/Xx4WRd7"><img src="https://i.imgur.com/Xx4WRd7.png" width="400px" height="400px" title="source: imgur.com" /></a></center>

코시분포는 location parameter인 $x_{0}$와 scale parameter인 $\gamma$를 가지는 분포이다. 이 분포의 확률밀도함수는:

>  $f(x)=\frac{1}{\pi \gamma \Big[1+(\frac{x-x_{0}}{\gamma})^{2} \Big] }=\frac{1}{\pi \gamma}\Big[\frac{\gamma^{2}}{(x-x_{0})^{2}+\gamma^{2}} \Big], -\infty < x_{0} < -\infty, \gamma > 0$

이며 $X \sim Cauchy(x_{0}, \gamma)$라고 표기한다. 코시분포는 평균과 분산이 정의되지 않으며 $x=x_{0}$일 때, 최빈값과 중위값만 가진다. 또한 $U,V \overset{ind}{\sim} N(0,1)$이라면 $U/V \sim Cauchy(0,1)$(standard Cauchy distribution)

**성질**

1. $X \sim Cauchy(x_{0}, \gamma)$이면 $kX+l \sim Cauchy(x_{0}k+l, \gamma \lvert k \lvert)$

2. $X \sim Cauchy(x_{0}, \gamma_{0}), Y \sim Cauchy(x_{1}, \gamma_{1})$ 이고 $X,Y$가 독립이라면 $X+Y \sim Cauchy(x_{0}+x_{1}, \gamma_{0}+\gamma_{1}), X-Y \sim Cauchy(x_{0}-x_{1}, \lvert \gamma_{0}-\gamma_{1} \lvert)$

3. $X \sim Cauchy(x_{0}, \gamma)$이면 $1/X \sim Cauchy(x_{0}, 1/\gamma)$이다.

4. 타 분포와의 관계
- $Cauchy(0,1) \overset{d}{\equiv} t(1)$
- $X \sim U(0,1)$이라면 $\tan(\pi(X-\frac{1}{2})) \overset{d}{\equiv} Cauchy(0,1)$  

## 카이제곱분포(Chi-squared distribution)

<center><a href="https://imgur.com/AnL04X5"><img src="https://i.imgur.com/AnL04X5.png" width="400px" height="400px" title="source: imgur.com" /></a></center>

$Z_{1},Z_{2},...,Z_{k} \overset{ind}{\sim} N(0,1)$일 때 $Z_{i}$들의 제곱합은 $\chi^{2}(k)$를 따른다. 즉 $X = \sum_{i=1}^{k}Z_{i}^{2} \sim \chi^{2}(k)$이다. 그리고 만약 $X \sim \chi^{2}(k)$이라면 그 확률밀도함수는

> $f(x) = \frac{1}{2^{\frac{k}{2}}\Gamma(\frac{k}{2})}x^{\frac{k}{2}-1}e^{-\frac{x}{2}}, k=2, 3 ...; x \geq 0$

**성질**

1. 카이제곱변수의 정의인 $X \sim N(0,1)$들의 제곱합에 따라서 $X_{1} \sim \chi^{2}(k_{1}), X_{2} \sim \chi^{2}(k_{2})$이라면 $X_{1}+X_{2} \sim \chi^{2}(k_{1}+k_{2})$이다.

2. 카이제곱분로는 감마분포의 특수한 경우이다. 만약 $X \sim \chi^{2}(k), Y \sim gamma(\alpha, \beta)$이라면 그 확률밀도 함수는 각각 다음과 같다:

> $f(x) = \frac{1}{2^{\frac{k}{2}}\Gamma(\frac{k}{2})}x^{\frac{k}{2}-1}e^{-\frac{x}{2}}, k=2,3...; x \geq 0$

>$f(y) = \frac{1}{\Gamma(\alpha)\beta^{\alpha}} y^{\alpha-1}e^{-y/\beta}, y \geq 0, \alpha>0, \beta>0$

위의 두식을 비교하면 $\alpha=\frac{k}{2}, \beta=2$일 때 두 개의 분포가 일치함을 확인할 수 있다. 즉, $\chi^{2}(k)=gamma(\frac{k}{2}, 2)$

3. $X \sim \chi^{2}(k)$이면 그 적률생성함수는 $(1-2t)^{(-k/2)}$이다.

4. $X \sim \chi^{2}(k)$이면 $E(X)=k, Var(X)=2k$이다.

**증명(3 계산)**

$X \sim \chi^{2}(k)$라고 하고 $E(e^{tX})$를 계산해보자($t<\frac{1}{2}$)

$$
\begin{align*}
  E(e^{tX})&= \frac{1}{2^{\frac{k}{2}}\Gamma(\frac{k}{2})}\int_{0}^{\infty}x^{\frac{k}{2}-1}e^{-\frac{x}{2}}e^{tx} dx \\
  &=\frac{1}{2^{\frac{k}{2}}\Gamma(\frac{k}{2})} \int_{0}^{\infty} x^{\frac{k}{2}-1}e^{x(t-1/2)}dx (put \ u = x(1/2-t))\\
  &=\frac{1}{2^{\frac{k}{2}}\Gamma(\frac{k}{2})} \int_{0}^{\infty}(\frac{u}{1/2-t})^{\frac{k}{2}-1}e^{-u}(\frac{du}{1/2-t}) \\
  &= \frac{1}{2^{k/2}\Gamma(k/2)}\frac{1}{(1/2-t)^{k/2}} \int_{0}^{\infty}u^{\frac{k}{2}-1}e^{-u} du
\end{align*}
$$

이 때 $ \int_{0}^{\infty}u^{\frac{k}{2}-1}e^{-u} du = \Gamma(k/2)$이므로

> $\frac{1}{2^{k/2}} \frac{1}{(1/2-t)^{k/2}}=(1-2t)^{-k/2}$

의 결과를 얻을 수 있다.
