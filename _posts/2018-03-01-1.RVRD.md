---
title: 1. Random variable and Probability distribution
category: Mathematical Statistics
tag: Mathematical Statistics
---

이 내용은 **수리통계학, 김우철, 민영사, 2012** 을 기반으로 합니다.

## 정의

일반적으로 여러 가지 결과가 가능하고 그 가능성을 확률로 나타낼 수 있는 실험을 **랜덤한 실험** 이라고 부르고 이러한 실험의 모든 가능한 결과의 집합인 표본공간에서 정의된 실수 값 함수를 **확률변수(random variable)** 이라고 한다.

### 이산형(discrete)

확률변수가 가질 수 있는 값들의 집합을 $$\{x_{1},x_{2},x_{3},...\}$$과 같이 나타낼 수 있을 때 그 확률변수를 **이산형** 이라 하고 각각의 값에 그 값을 가질 확률을 대응시키는 함수 즉,

> $$f(x_{k})=P(X=x_{k})(k=1,2,3,...) $$

를 $$X$$의 **확률질량함수(probability mass function)** 라고 한다. 이는 다음과 같은 성질을 만족한다:

* $$f(x) \geq 0$$, $$-\infty < x < \infty$$, $$f(x)=0$$, $$x \neq x_{k}(k=1,2,...)$$
* $\sum_{x} f(x) = \sum_{k=1}^{\infty} f(x_{k})$ $=1$
* $\sum_{a \leq x \leq b}f(x) =$ $P(a \leq X \leq b)$

### 연속형(continuous)

확률변수가 실수 구간의 값들을 가질 수 있고 그에 관한 확률이 적분으로 주어질 때, 그 확률변수를 **연속형** 이라 하고 확률을 정해주는 함수, 즉

> $$\int_{a}^{b} f(x) dx = P(a \leq X \leq b) \ (-\infty < a < b < \infty)$$

인 함수 $$f$$를 $$X$$의 **확률밀도함수(probability density function)** 라고 한다. 때론 이를 $$pdf$$라고 부른다. 이는 다음과 같은 성질을 만족한다:

* $$f(x) \geq 0$$, $$-\infty < x < \infty$$
* $\int_{-\infty}^{+\infty} f(x) dx$ $= 1$  
* $\int_{a}^{b} f(x) dx = P(a \leq X \leq b) $ $(-\infty < a < b < \infty)$

연속형 확률변수의 경우에는 한 점에서의 적분 값이 0이므로

> $$P(X=a)=\int_{a}^{a} f(x) dx = 0$$

이고 따라서 $$f(a) \neq P(X=a)$$이다. 다만 다음의 근사식만 성립한다.

> $$\Delta x \approx 0, P(a \leq X \leq a+\Delta x) \approx f(a)\Delta x$$

## 확률분포 특성치

확률변수 $$X$$의 확률밀도함수가 $$f$$일 때, $$X$$의 확률분포의 평균은 이산형, 연속형 각각:

> $$\mu_D = \sum_{x} xf(x)$$, $$\mu_C=\int_{-\infty}^{\infty}xf(x) dx$$

확률변수 $$X$$의 함수 $$g(X)$$의 기댓값은 이산형, 연속형 각각:

> $$E_D[g(X)]=\sum_{x}g(x)f(x)$$, $$E_C[g(X)]=\int_{-\infty}^{\infty}g(x)f(x)dx$$

확률변수 $$X$$의 확률밀도함수와 평균이 각각 $$f, \mu$$라고 할 때 분산과 표준편차는:

> $$Var(X) = E[(X-\mu)^{2}]=\sum_{x}(x-\mu)^{2}f(x) \ or \ \int_{-\infty}^{\infty}(x-\mu)^{2}f(x)dx $$

한편, 평균이나 분산이 실수로 정의될 수 없는 확률분포 역시 존재한다. 예를 들어:

> $$f(k)=P(X=k)=\frac{1}{k(k+1)}, k=1,2,...$$

## 누적분포함수 생성함수

이산형 확률변수 $$X$$의 확률밀도함수가 $$f(x_{k})=P(X=x_{k})(k=1,2,...)$$라고 할 때, X의 누적 확률을 나타내는 함수:

> $$F(x)=P(X \leq x) = \sum_{t \leq x} f(t) $$

를 X의 누적분포함수(cumulative distribution function)라고 한다. 만약 $$x_{1} < x_{2} < \cdots < x_{n-1} < x_{n}$$인 경우에:

> $$F(x_{n})=\sum_{k=1}^{n}f(x_{k}), f(x_{n})=F(x_{n})-F(x_{n-1})$$

연속형 확률변수 $$X$$의 확률밀도함수가 $$f$$일 때, $$X$$의 누적 확률을 나타내는 함수

> $$F(x)=P(X \leq x)=\int_{-\infty}^{x} f(t) dt $$

를 $X$의 누적분포함수라고 한다. 특히, $f$가 연속인 $x$에 대하여는

> $\frac{d}{dx}F(x)=f(x)$

음이 아닌 정수의 값을 가질 수 있는 이산형 확률변수 $X$와 그 확률밀도함수 $f$에 대해

> $f(x)=P(X=x), x-0,1,... $

이를 통해서 $(f(0),f(1),f(2), \cdots)$의 값들이 $X$의 분포를 정하는 것을 알 수 있다. 그런데 이들과 일대일 대응하는 것은

> $f(0)s^{0} + f(1)s^{1} + f(2)s^{2} + \cdots = \sum_{x=0}^{\infty}s^{x}f(x), \ -1 < s < 1$

이 멱급수를 반복적으로 미분하여 $f(k)$ 값들을 구할 수 있다:

$\frac{d^{k}}{ds^{k}} \Big \{ \sum_{x=0}^{\infty}s^{x}f(x) \Big \}=\sum_{x=k}^{\infty}x(x-1)\cdots(x-k+1)s^{x-k}f(x), \ -1 < s < 1$

이러한 뜻에서 이 멱급수인

> $G(s)=E[s^{X}] = \sum_{x=0}^{\infty} s^{x}f(x), \ -1 < s < 1$

를 이와 같은 확률변수 $X$의 확률생성함수(probability generating function)이라고 한다. 확률생성함수 $G(s)$의 정의에서 $s$가 양수이면

> $ G(s)=E(s^{X})=\sum_{k=1}^{\infty}s^{k}(1/2)^{k} = s/(2-s), \ -2 < s < 2 $

와 같이 나타낼 수 있으므로 $E(e^{tX})$도 분포를 정할 수 있음을 알 수 있다. 일반적으로 0을 포함하는 열린구간의 $t$ 값에 대하여 $E(e^{tX})$가 실수 일 때, 함수

> $ M(t)=E(e^{tX}), \ -h < t < h (\exists h > 0) $

를 확률변수 X의 **적률생성함수(moment generating function, mgf)** 라고 한다.

**EXAMPLE**

앞면이 나올 때까지 동전을 던지게 될 횟수 $X$의 확률밀도함수는
> $ f(k) = P(X=k) = (1/2)^{k}(k=1,2,...)$

이므로, $X$의 mgf는 다음과 같다:

> $M(t) = E(e^{tX}) = \sum_{k=1}^{\infty} e^{tk}(1/2)^{k} = (e^{t}/2)/(1-e^{t}/2), \ t < \log2$

한편, 지수함수의 멱급수 전개식으로부터 $e^{tX}=1+\frac{tX}{1!}+\frac{(tX)^{2}}{2!}+\cdots+\frac{(tX)^{k}}{k!}+\cdots$이다. 양변에 기댓값을 취하면:

> $M(t)=E(e^{tX})=1+\frac{E(X)}{1!}t+\frac{E(X^{2})}{2!}t^{2}+\cdots+\frac{E(X^{k})}{k!}t^{k}+\cdots$

이다. 이 때 전개식의 각 항에서 나오는 $E(X^{k}(k=1,2,3...)$를 $X$의 **$k$차 적률(moment)** 라고 하며 기호로 $m_{k}(X)$ 혹은 $m_{k}$로 표기한다.

**성질**

1. **(Moment generating property)** 확률변수 $X$의 적률생성함수가 존재하면, 즉

> $ M(t)=E(e^{tX}) < \infty, \ -h < t < h (\exists h > 0)$

이면 $X$의 모든 적률이 존재하고

> $E(X^{k})=M^{(k)}(0), M(t)=\sum_{k}^{\infty} \frac{E(X^{k})}{k!}t^{k}, \ -\epsilon < t < \epsilon(\exists \epsilon > 0)$

2. **(Distribution determinability)** 두 확률변수 $X, Y$의 적률생성함수 $M_{X}(t), M_{Y}(t)$가 존재하고 0을 포함하는 열린 구간에서 일치한다면, 즉

>  $M_{X}(t) = M_{Y}(t), \ -h < t < h(\exists h > 0)$

이면, X와 Y의 확률분포가 일치한다.

**증명**

1.에 대한 증명: 지수함수의 멱급수 전개식

> $e^{a} = 1+\frac{a}{1!} + \frac{a^{2}}{2!} + \cdots + \frac{a^{k}}{k!} + \cdots$

이를 통해 다음 부등식을 구할 수 있다.

> $(\lvert tx\lvert )^{k}/k! \leq e^{\lvert tx\lvert } \leq e^{tx} + e^{-tx}$

양 끝변에 기댓값을 취하면

> $ \lvert t\lvert ^{k}E(\lvert X\lvert ^{k})/k! \leq M(t) + M(-t) < \infty \ (-h < t < h)$

으로 $X$의 모든 적률이 존재한다.

## 여러가지 부등식들

### Jensen's inequality

수직선 위의 구간 I 에서의 값을 갖는 학률변수 X의 기댓값이 존재하면, 구간 I에서 볼록한 함수 $\phi$에 대하여 다음 부등식이 성립한다.

> $ \phi(E(X)) \leq E(\phi(X)) $

한편 볼록함수란 아래의 조건을 만족하는 함수 $\phi$이다.

> $ \phi(\lambda x + (1-\lambda)y) \leq \lambda \phi(x) + (1-\lambda)\phi(y), \ (0 \leq \lambda \leq 1) $

### Liapounov inequality

확률변수 $X$에 대하여 $E(\lvert X\lvert ^{s}) < \infty$이면 $0 < r < s$ 인 $r$에 대해서

> $(E[\lvert X\lvert ^{r}])^{1/r} \leq (E[\lvert X\lvert ^{s}])^{1/s}$

**증명**

$p>1$이면 함수 $\phi(y)=y^{p}, y \geq 0$는 볼록함수이다. 따라서 0 이상의 값을 가지는 확률변수 $Y$의 기대값이 존재한다면 Jensen's inequality에 의해 다음이 성립한다:

> $ (E[Y])^{p} \leq E[Y^{p}] $

여기서 $p=s/r>1, Y=\lvert X\lvert ^{r}$이라고 하면

> $ E[Y] = E[\lvert X\lvert ^{r}(I_{\lvert X\lvert  \leq 1} + I_{\lvert X\lvert >1})] \leq E[1+\lvert X\lvert ^{s}] < \infty $\\
$ (E[\lvert X\lvert ^{r}])^{s/r} = (E[Y])^{p} \leq E(Y^{p}) = E[(\lvert X\lvert ^{r})^{s/r}]=E[\lvert X\lvert ^{s}] $

### Markov inequality

확률변수 $Z$에 대하여 $E(\lvert Z\lvert ^{r}) < \infty, (r>0)$이면 임의의 양수 $k$에 대하여는

> $P(\lvert Z\lvert  \geq k) \leq E(\lvert Z\lvert ^{r})/k^{r}$

**증명**

$P(\lvert Z\lvert  \geq k)=E(I_{\lvert Z\lvert  \geq k})$ 이다. 그리고 지표함수는 0 또는 1이므로 $I_{(\lvert Z\lvert  \geq k)} = 1 \times I_{(\lvert Z\lvert /k \geq 1)} \leq (\lvert Z\lvert /k)^{r} \times I_{(\lvert Z\lvert /k \geq 1)} \leq \lvert Z\lvert ^{r}/k^{r}$ 따라서 양변에 기댓값을 취하면:

> $P(\lvert Z\lvert  \geq k)=E(I_{\lvert Z\lvert  \geq k}) \leq E(\lvert Z\lvert ^{r})/k^{r}$

### Chebyshev inequality

확률변수 $X$에 대하여 $Var(X) < \infty$이면, 임의의 양수 $k$에 대하여

> $ P(\lvert X-E(X)\lvert \geq k) \leq Var(X)/k^{2} $

**증명**

*Markov inequality* 에서 $Z=X-E(X) r=2$를 대입하면 해당 결과를 얻는다.

**EXAMPLE**

확률변수 $X$의 평균, 표준편차를 각각 $\mu, \sigma(0<\sigma<\infty)$라고 하면 *Chebyshev inequality* 에 의해 쉽게 다음의 결과를 얻을 수 있다.

> $P(\lvert X-\mu\lvert  \geq 6\sigma) \leq 1/36 \approx 0.0277$
