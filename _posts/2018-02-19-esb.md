---
title: 앙상블 기법(Ensemble Learning Method)
category: Basic Machine Learning Algorithm
tag: Ensemble
---

Machine Learning을 하다보면 알고리즘 그리고 모수에 따라 서로 다른 모델들이 만들어 지게 됩니다. 물론, 그에 따른 성능 역시 다릅니다. A 알고리즘으로 만들어진 A.model이 있고 B 알고리즘으로 만든 B.model이 있고 accuracy가 각각 0.9, 0.85이라고 하면, 이 데이터에서는 A 알고리즘이 더 성능이 좋은 것 을 알 수 있습니다. 하지만 B 알고리즘도 사용하지 않기는 아쉽습니다. **앙상블 기법(Ensemble Learning Method)은 이러한 상황에서 복수의 모델들을 동시에 고려해서 더 좋은 성능을 내는 것을 목표로 합니다.** 이 글에서는 대표적인 앙상블 기법인 **배깅(Bagging = Bootstrap aggregating)**과 **부스팅(Boosting)** 에 대해서 다루겠습니다. 참고자료는 wikipedia 입니다.

## Bias & Variance tradeoff

앙상블 기법의 목적이 모델들이 가지고 있는 오류를 줄이는 것이므로, Machine Learning을 함에 있어서 모델의 오류부터 알아봅시다. 데이터 $$\mathcal{D} = (X, y)$$가 주어졌을 상황에서 데이터에 대응되는 $$y$$의 분산을 $$Var(y)=\sigma^{2}$$라 합시다. 그리고 완벽하게 $$y=f(X)$$인 $$f$$을 가정하고 $$X$$로 인해서 추정되는 Machine Learning 모델을 $$\hat{f}(X)$$(이하 $$\hat{f}$$)이라고 합시다. 이 때의 오류는 $$E[(y-f)^2]$$라고 할 수 있습니다.((정답 - 추정값)의 제곱꼴) 그리고 이는 아래와 같이 전개됩니다.

$$
\begin{align*}
  E[(y-f)^2] &= E[y^{2}+\hat{f}^{2}-2y\hat{f}] \\
  &= E[y^{2}] + E[\hat{f}^{2}] - E[2y\hat{f}] \\
  &= Var[y] + E[y]^{2} + Var[\hat{f}] + E[\hat{f}]^{2} -2fE[\hat{f}] \\
  &= Var[y] + Var[\hat{y}] + (f^{2} - 2fE[\hat{f}] + E[\hat{f}]^{2}) \\
  &= Var[y] + Var[\hat{f}] + (f-E[\hat{f}])^{2} \\
  &= \sigma^{2} + Var[\hat{f}] + Bias[\hat{f}]^{2}
\end{align*}
$$

전개과정은 $$Var[X] = E[X^{2}] - E[X]^{2}$$을 이용하면 됩니다. 결과에서 보이듯이 모델의 오류는 **Variance + Bias** 꼴로 풀 수 있습니다. 모델의 Variance는 training data에 있는 Variance 때문에 발생합니다. 데이터의 노이즈까지 모델링에 포함시켜버리기 때문에 **과적합(overfitting)** 문제가 발생할 때 높아집니다. 한편 모델의 Bias는 추정된 모델이 y 값을 잘 맞추지 못할 때 발생하는 문제입니다. 학습을 했음에도 불구하고 **과소적합(underfitting)** 문제가 생기는 것 입니다. 두 가지를 잘 드러내는 그림이 있습니다.

<center><a href="https://imgur.com/YjsMLKT"><img src="https://i.imgur.com/YjsMLKT.png" width="500px" height="500px" title="source: imgur.com" /></a></center>

한편, 수식에서도 알 수 있듯이 Variance와 Bias는 tradeoff 관계에 있습니다. Variance를 줄이기 위해서 모델을 간소하게 하면 Bias가 높아지고, Bias를 줄이기 위해서 모델 복잡도를 올리면 과적합이 되어서 Variance가 높아집니다. 그래서 둘 사이의 균형을 잡는 것이 중요합니다. 앙상블 기법은 둘 사이의 교환을 효과적으로 해줍니다. 즉, Bias를 조금만 높이면서 Variance를 많이 낮출 수 있습니다.

## Bagging

**배깅(Bagging)** 은 앙상블 기법 중 하나로 불안정한 학습 알고리즘의 예측력을 획기적으로 향상시킬 수 있습니다. 또한 이는 training data를 모집단으로 생각하고 이로부터 데이터를 계속해서 복원추출해서 만든 모델들의 평균 예측 모형을 구한 것으로 Variance를 줄일 수 있습니다. 그렇기에 배깅은 Bias가 작고 Variance가 큰 단일 모델들을 사용한다면 큰 효과를 거둘 수 있습니다. 구체적인 과정:

1.    training data에서 여러 개의 sample를 복원추출로 뽑습니다.
2.    각각의 sample로 단일 모델들을 학습시킵니다.
3.    Regression의 경우 평균, Classification의 경우 투표를 통해서 모델들을 결합하여 최종 모형을 만듭니다.

<center><a href="https://imgur.com/q6HNImH"><img src="https://i.imgur.com/q6HNImH.png" width="500px" height="500px" title="source: imgur.com" /></a></center>

여기서 평균 예측 모형의 성능이 항상 단일 모델보다는 좋을 것 같다고 직관적으로는 알 수 있지만, 정말 좋은지 의문이 들 수 있습니다. 이를 간단하게 증명하겠습니다. training data를 $$\mathcal{D}$$라하고 이를 통해 만들어진 모델을 $$\hat{f}(x)$$라고 합시다. 또한, 평균예측모형 $$\hat{f}_{A}(x)=E_{\mathcal{D}}[\hat{f}(x)]$$이라고 하면 아래와 같은 정리가 항상 성립합니다.

**THOREM**

$$(X, Y)$$를 $$\mathcal{D}$$와 독립인 미래의 데이터라고 하자 $$\hat{f}(x), \hat{f}_{A}(x)$$에 대하여 제곱합으로 오류를 정의한다면 각각 $$R = E_{(X,Y)}[E_{\mathcal{D}}[(Y-\hat{f}(X))^{2}]], \ R_{A} = E_{(X,Y)}[(Y-\hat{f}_{A}(X))^{2}]$$ 이다. 그러면 항상 $$R \geq R_{A}$$가 성립한다.

**PROOF**

제곱함수 $$g(x)=x^{2}$$은 볼록함수(convex function)이므로 $$Jensen's \ Inequality$$에 의해서 $$g(E[X]) \leq E[g(X)]$$가 성립합니다. 그러므로 $$f_{A}^{2}(X)=(E_{\mathcal{D}}[\hat{f}(x)])^{2} \leq E_{\mathcal{D}}[(\hat{f}(x))^{2}]$$가 성립합니다. 양변에 $$E_{(X,Y)}$$을 취하면, $$E_{(X,Y)}[f_{A}^{2}(X)]=E_{(X,Y)}[(E_{\mathcal{D}}[\hat{f}(x)])^{2}] \leq E_{(X,Y)}[E_{\mathcal{D}}[(\hat{f}(x))^{2}]]$$ 역시 성립함을 알 수 있습니다. 따라서:

$$
\begin{align*}
  R &= E_{(X,Y)}[Y^{2}] - 2E_{(X,Y)}[YE_{\mathcal{D}}\hat{f}(X)] + E_{(X,Y)}[E_{\mathcal{D}}[]\hat{f}^{2}(X)] \\
    &= E_{(X,Y)}[Y^{2}] - 2E_{(X,Y)}[Yf_{A}(X)] + E_{(X,Y)}[f_{A}^{2}(X)] \\
    &= E_{(X,Y)}[(Y-\hat{f}_{A}(X))^{2}] = R_{A}
\end{align*}
$$

$$R \geq R_{A}$$이 항상 성립하는 것을 알 수 있습니다. 이를 통해 분산이 줄어드는 것을 확인할 수 있습니다: $$Var(\hat{f}(X))=R=E_{(X,Y)}[E_{\mathcal{D}}[(Y-\hat{f}(X))^{2}]] \geq E_{(X,Y)}[(Y-\hat{f}_{A}(X))^{2}]=R_{A}=Var(\hat{f}_{A}(X))

## Boosting
