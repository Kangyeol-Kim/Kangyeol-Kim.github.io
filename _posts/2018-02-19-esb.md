---
title: 앙상블 기법(Ensemble Learning Method)
category: Basic Machine Learning Algorithm
tag: Ensemble
---

Machine Learning을 하다보면 알고리즘 그리고 모수에 따라 서로 다른 모델들이 만들어 지게 됩니다. 물론, 그에 따른 성능 역시 다릅니다. A 알고리즘으로 만들어진 A.model이 있고 B 알고리즘으로 만든 B.model이 있고 accuracy가 각각 0.9, 0.85이라고 하면, 이 데이터에서는 A 알고리즘이 더 성능이 좋은 것 을 알 수 있습니다. 하지만 B 알고리즘도 사용하지 않기는 아쉽습니다. **앙상블 기법(Ensemble Learning Method)은 이러한 상황에서 복수의 모델들을 동시에 고려해서 더 좋은 성능을 내는 것을 목표로 합니다.** 이 글에서는 대표적인 앙상블 기법인 **배깅(Bagging = Bootstrap aggregating)**과 **부스팅(Boosting)** 에 대해서 다루겠습니다. 참고자료는 wikipedia 입니다.

## Bias & Variance tradeoff

앙상블 기법의 목적이 모델들이 가지고 있는 오류를 줄이는 것이므로, Machine Learning을 함에 있어서 모델의 오류부터 알아봅시다. 데이터 $$\mathcal{D} = (X, y)$$가 주어졌을 상황에서 데이터에 대응되는 $$y$$의 분산을 $$Var(y)=\sigma^{2}$$라 합시다. 그리고 완벽하게 $$y=f(X)$$인 $$f$$을 가정하고 $$X$$로 인해서 추정되는 Machine Learning 모델을 $$\hat{f}(X)$$(이하 $$\hat{f}$$)이라고 합시다. 이 때의 오류는 $$E[(y-\hat{f})^2]$$라고 할 수 있습니다.((정답 - 추정값)의 제곱꼴) 그리고 이는 아래와 같이 전개됩니다.

$$
\begin{align*}
  E[(y-f)^2] &= E[y^{2}+\hat{f}^{2}-2y\hat{f}] \\
  &= E[y^{2}] + E[\hat{f}^{2}] - E[2y\hat{f}] \\
  &= Var[y] + E[y]^{2} + Var[\hat{f}] + E[\hat{f}]^{2} -2fE[\hat{f}] \\
  &= Var[y] + Var[\hat{f}] + (f^{2} - 2fE[\hat{f}] + E[\hat{f}]^{2}) \\
  &= Var[y] + Var[\hat{f}] + (f-E[\hat{f}])^{2} \\
  &= \sigma^{2} + Var[\hat{f}] + Bias[\hat{f}]^{2}
\end{align*}
$$

전개과정은 $$Var[X] = E[X^{2}] - E[X]^{2}$$을 이용하면 됩니다. 결과에서 보이듯이 모델의 오류는 **Variance + Bias** 꼴로 풀 수 있습니다. 모델의 Variance는 training data에 있는 Variance 때문에 발생합니다. 데이터의 노이즈까지 모델링에 포함시켜버리기 때문에 **과적합(overfitting)** 문제가 발생할 때 높아집니다. 한편 모델의 Bias는 추정된 모델이 y 값을 잘 맞추지 못할 때 발생하는 문제입니다. 학습을 했음에도 불구하고 **과소적합(underfitting)** 문제가 생기는 것 입니다. 두 가지를 잘 드러내는 그림이 있습니다.

<center><a href="https://imgur.com/YjsMLKT"><img src="https://i.imgur.com/YjsMLKT.png" width="500px" height="500px" title="source: imgur.com" /></a></center>

한편, 수식에서도 알 수 있듯이 Variance와 Bias는 tradeoff 관계에 있습니다. Variance를 줄이기 위해서 모델을 간소하게 하면 Bias가 높아지고, Bias를 줄이기 위해서 모델 복잡도를 올리면 과적합이 되어서 Variance가 높아집니다. 그래서 둘 사이의 균형을 잡는 것이 중요합니다. 앙상블 기법은 둘 사이의 교환을 효과적으로 해줍니다.

## Bagging

**배깅(Bagging)** 은 앙상블 기법 중 하나로 불안정한 학습 알고리즘의 예측력을 획기적으로 향상시킬 수 있습니다. 또한 이는 training data를 모집단으로 생각하고 이로부터 데이터를 계속해서 복원추출해서 만든 모델들의 평균 예측 모형을 구한 것으로 **Variance를 줄일 수 있습니다.** 그렇기에 배깅은 Bias가 작고 Variance가 큰 단일 모델들을 사용한다면 큰 효과를 거둘 수 있습니다. 구체적인 과정:

1.    training data에서 여러 개의 sample를 복원추출로 뽑습니다.
2.    각각의 sample로 단일 모델들을 학습시킵니다.
3.    Regression의 경우 평균, Classification의 경우 투표를 통해서 모델들을 결합하여 최종 모형을 만듭니다.

<center><a href="https://imgur.com/q6HNImH"><img src="https://i.imgur.com/q6HNImH.png" width="500px" height="500px" title="source: imgur.com" /></a></center>

여기서 평균 예측 모형의 성능이 항상 단일 모델보다는 좋을 것 같다고 직관적으로는 알 수 있지만, 정말 좋은지 의문이 들 수 있습니다. 이를 간단하게 증명하겠습니다. training data를 $$\mathcal{D}$$라하고 이를 통해 만들어진 모델을 $$\hat{f}(x)$$라고 합시다. 또한, 평균예측모형 $$\hat{f}_{A}(x)=E_{\mathcal{D}}[\hat{f}(x)]$$이라고 하면 아래와 같은 정리가 항상 성립합니다.

**THOREM**

$$(X, Y)$$를 $$\mathcal{D}$$와 독립인 미래의 데이터라고 하자 $$\hat{f}(x), \hat{f}_{A}(x)$$에 대하여 제곱합으로 오류를 정의한다면 각각 $$R = E_{(X,Y)}[E_{\mathcal{D}}[(Y-\hat{f}(X))^{2}]], \ R_{A} = E_{(X,Y)}[(Y-\hat{f}_{A}(X))^{2}]$$ 이다. 그러면 항상 $$R \geq R_{A}$$가 성립한다.

**PROOF**

제곱함수 $$g(x)=x^{2}$$은 볼록함수(convex function)이므로 $$Jensen's \ Inequality$$에 의해서 $$g(E[X]) \leq E[g(X)]$$가 성립합니다. 그러므로 $$f_{A}^{2}(X)=(E_{\mathcal{D}}[\hat{f}(x)])^{2} \leq E_{\mathcal{D}}[(\hat{f}(x))^{2}]$$가 성립합니다. 양변에 $$E_{(X,Y)}$$을 취하면, $$E_{(X,Y)}[f_{A}^{2}(X)]=E_{(X,Y)}[(E_{\mathcal{D}}[\hat{f}(x)])^{2}] \leq E_{(X,Y)}[E_{\mathcal{D}}[(\hat{f}(x))^{2}]]$$ 역시 성립함을 알 수 있습니다. 따라서:

$$
\begin{align*}
  R &= E_{(X,Y)}[Y^{2}] - 2E_{(X,Y)}[YE_{\mathcal{D}}\hat{f}(X)] + E_{(X,Y)}[E_{\mathcal{D}}[\hat{f}^{2}(X)]] \\
    &= E_{(X,Y)}[Y^{2}] - 2E_{(X,Y)}[Yf_{A}(X)] + E_{(X,Y)}[f_{A}^{2}(X)] \\
    &= E_{(X,Y)}[(Y-\hat{f}_{A}(X))^{2}] = R_{A}
\end{align*}
$$

$$R \geq R_{A}$$이 항상 성립하는 것을 알 수 있습니다. 이를 통해 분산이 줄어드는 것을 확인할 수 있습니다: $$Var(\hat{f}(X))=R=E_{(X,Y)}[E_{\mathcal{D}}[(Y-\hat{f}(X))^{2}]] \geq E_{(X,Y)}[(Y-\hat{f}_{A}(X))^{2}]=R_{A}=Var(\hat{f}_{A}(X))$$

## Boosting

**Boosting** 기법의 주된 목적은 **Bias를 줄이는 데** 있습니다. 대부분의 boosting 알고리즘은 반복적으로 weak model을 학습하여 학습된 결과로 strong model을 만드는 것 입니다. weak model이 학습된 이후에는 예측이 틀린 데이터에 대해서는 가중치를 부여하고, 예측이 잘된 데이터에 대해서는 가중치를 약화합니다. 따라서 그 다음 학습때는 전에 잘못 분류한 데이터에 집중하여 학습하게 됩니다. 이러한 Boosting 방법은 매우 많으므로 여기서는 그 중 대표적인 알고리즘인 **Adaboost(Adaptive Boosting)** 에 대해서 다루겠습니다. Adaboost는 (1) training data 전체로 성능이 약한 모델을 학습시키고 (2) 모델이 잘못 분류한 관측치는 가중치 증가/ 제대로 분류된 관측치는 가중치 감소 (3) 부여된 가중치로 다시 모델을 학습 (4) (2)~(3)을 반복하여 만든 모델들을 결합합니다.

<center><a href="https://imgur.com/QXtMrru"><img src="https://i.imgur.com/QXtMrru.png" width="400px" height="400px" title="source: imgur.com" /></a></center>

종속변수가 -1 혹은 1인 데이터 $$n$$개가 주어졌을 때 정확히 돌아가는 과정은:

1.    가중치 $$w_{i}=\frac{1}{n}, \ i=1,...,n$$를 초기화 한다.

2.    $$m=1,...,M$$에 대하여 아래의 과정을 반복한다.
* 가중치 $$w_{i}$$를 이용하여 분류기 $$f_{m}(x) \in \{-1,1\}$$를 적합한다.
* $$error_{m}=\frac{\sum_{i=1}^{n} w_{i}I(y_{i} \neq f_{m}(x_{i}))}{\sum_{i=1}^{n} w_{i}}$$ 로 계산한다.
* $$c_{m} = \frac{1-error_{m}}{error_{m}} $$로 설정한다.
* 가중치 $$w_{i}$$을 $$w_{i} = w_{i} \times c_{m}I(y_{i} \neq f_{m}(x_{i}))$$으로 업데이트 합니다. 이 때 $$error_{m} \geq 0.5$$ 일 때, $$c_{m} \geq 1$$로 가중치가 커지는 것을 알 수 있습니다.

3.    2단계에서 얻은 M개의 분류기를 결합하여 최종 분류기 $$sign(\sum_{m=1}^{M} c_{m} f_{m}(x))$$를 얻습니다.

부스팅은 주로 Bias를 줄일 수 있습니다. 하지만 그만큼 Variance가 늘어나 과적합되는 경향이 있습니다. 따라서 부스팅은 Bias가 크고 Variance가 작은 모형들을 가지고 알고리즘들이 적용시키는 것이 적합합니다.
