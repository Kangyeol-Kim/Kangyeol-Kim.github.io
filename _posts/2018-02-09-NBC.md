---
title: Naive Bayes Classifier
category: Basic Machine Learning Algorithm
tag: Classification
---

나이브 베이즈 분류기(이하 NBC)는 지도 학습(Supervised Learning) 환경에서 작동하는 Classifier 중 하나입니다. 이번 글에서는 NBC가 어떤 구조로 되어있는지 구체적으로 살펴보고 그에 필요한 몇 가지 통계적 개념에 대해서 살펴보겠습니다. (1) 조건부 확률&베이즈 정리, 조건부 독립, MLE / (2) NBC 모델의 작동 원리 / (3) 그 외 다른 것 (wikipedia를 참조했음을 밝힙니다.)

# 쓰이는 통계적 개념

### 조건부 확률&베이즈 정리

사건 A,B가 있을 때, **B가 일어 났을 때 A의 확률** 을 $$P(A \lvert B)$$라고 표기합며 이를 사건 B가 일어났을 때 사건 A의 조건부 확률이라고 부릅니다. 한편, 조건부 확률은 **베이즈 정리** 에 의해 다르게 풀어 쓸 수도 있습니다.

>$$ P(A|B)=\frac{P(A,B)}{P(B)}=\frac{P(B|A)P(A)}{P(B)} $$

중요한 것은 사건 B가 일어났을 때 사건 A의 조건부 확률을 사건 A가 일어났을 때 사건 B의 조건부 확률로 나타낼 수 있다는 것 입니다.

### 조건부 독립

사건 F,G가 H가 주어진 상황에서 조건부 독립이라는 말은 H라는 상황이 주어진다면 F,G는 서로 상관없는 독립적인 사건이라는 말입니다. 수식으로 나타내면 아래와 같이 됩니다:

$$P(F \cap G|H)=P(F|H)P(G|H)$$

두 사건이 상관없으니 확률이 따로따로 곱한 것과 같이 됩니다.

### Maximum Likelihood(MLE)

MLE는 데이터들을  통해 데이터들의 모수(parameter)를 구하는 방법입니다. 어떤 모수(parameter)가 주어졌을 때, 원하는 값들이 나올 Likelihood 를 최대로 만드는 모수를 선택하는 방법입이다. 갑자기 어려운 말들이 쏟아져 나왔는데, 여기서는 데이터들이(\{x_{1},...,x_{n}\}) 각각 독립적으로 특정한 분포($$f(\cdot \lvert \theta)$$)에서 sampling 됬다고 생각합니다. 그리고 $$n$$개의 데이터가 동시에 관찰된 확률 분포를 Likelihood라고 부르며 이를 $$L(\theta)=\prod_{i=1}^{n} f(x_{i} \lvert \theta)$$라고 정의합니다. MLE 방식은 이러한 Likelihood가 최대로 만드는 $$\theta$$값을 찾는 것 입니다. 아래서 다시 한 번 언급하겠지만, NBC 모델에서는 연속형 변수가 정규 분포(normal distribution)을 따르고 범주형 변수들은 다항 분포(Multinomial distribution)을 따른다고 생각합니다. 그리고 MLE 방식 가지고 데이터들을 통해서 분포들의 모수를 구합니다.

# NBC 모델의 작동 원리

주어진 데이터가 $$(x_{1},...,x_{p})$$와 같은 형태이고, 그에 따른 분류가 $$(C_{1},...C_{m})$$으로 된다고 합시다. NBC의 목적은 $$(x_{1},...,x_{p})$$가 주어졌을 때 $$C_{k}(1 \leq k \leq m)$$의 조건부 확률들을 구해서 그 중 확률값이 maximize하는 $$C_{k}$$로 분류를 하는 것입니다.

## 모델 구조

다시 말해, $$m$$개의 $$P(C_{k} \lvert x_{1},...,x_{p})$$를 계산해서 이를 비교하면 됩니다. 먼저 계산해 봅시다.

$$
\begin{align*}
  P(C_{k}|x_{1},...,x_{p})&=\frac{P(x_{1},...,x_{p}|C_{k})P(C_{k})}{P(x_{1},...,x_{p})} \\
  &\propto P(x_{1},...,x_{p}|C_{k})P(C_{k}) \\
  &= P(x_{1}|C_{k}) \cdots P(x_{p}|C_{k})P(C_{k})
\end{align*}
$$

첫 번째 줄은 **베이즈 정리** 에 의해 알 수 있습니다. 또한 분모의 $$P(x_{1},...,x_{p})$$ 부분은 모든 $$C_{k}$$에 대해서 공통으므로 날릴 수 있습니다. 그리고 **$$C_{k}$$가 주어 졌을 때 $$(x_{1},...,x_{p})$$의 조건부 독립** 을 가정한다면, 마지막까지 계산할 수 있습니다. 이제 $$P(x_{1}\lvert C_{k}),...,P(x_{p}|C_{k}),P(C_{k})$$를 계산해야 합니다. 하지만 그를 위해서는 먼저 MLE 방식으로 각 모수를 구해야 합니다.

## 모수 추정

구해야 할 모수는 training data를 $$C_{k}$$에 따라서 나눈 후 각각 $$C_{k}$$마다 연속형 변수인 경우는 정규분포를 따른다고 했으니까, 평균과 분산/ 범주형 변수인 경우에는 다항분포를 따른다고 했으니 각 범주의 확률을 구해주면 됩니다. 또한 $$P(C_{k})$$는 training data 중 $$C_{k}$$의 비율로 구해주면 됩니다. MLE 추정치 계산의 결과는 직관적으로 와닿게 구해 집니다. 예를 들어 $$C_{1}$$에 대해서 모수를 구한다고 생각합시다. $$X_{1}$$은 연속형, $$X_{2}$$는 범주가 3개인 범주형 변수라고 하고, 전체 training data는 $$n$$개 $$C_{1}$$에 속하는 데이터는 $$m$$개라고 하죠. 이에 따른 모수추정은:

$$
  \mu_{1}=\frac{1}{m} \sum_{i=1}^{m} x_{1i}, \ \ \sigma_{1}=\frac{1}{m} 	\sum_{i=1}^{m} (x_{1i}-\mu_{1})^2 (평균과 표준 편차)\\
  p_{11}=\frac{\#(C_{1},<1>)}{m},p_{12}=\frac{\#(C_{1},<2>)}{m},p_{13}=\frac{\#(C_{1},<3>)}{m} (숫자 세기) \\
  P(C_{1})=\frac{m}{n}
$$

평균과 분산은 그냥 해당 데이터의 평균과 분산을 구하면 됩니다. 또한 각 범주의 확률은 $$C_{1}$$에 속하는 자료 중 각 범주에 속하는 비율로 구할 수 있습니다.

## 모수 추정과 예측의 예시

### 모수 추정 예시

간단한 예를 가지고 NBC가 만들어 지는 과정을 살펴봅시다. 아래와 같은 데이터를 가지고 목표는 지원자의 합불을 예측하는 NBC 모델을 만들고 싶다고 합시다. 즉, $$C_{1}$$=합/$$C_{2}$$=불

| 합불 | 서류 점수 | 면접 점수 | 석사 여부 |
| :-----: | :-----: | :-----: | :-----: |
합 | 10 | 10 | x |
합 | 8 | 9 | o |
불 | 8 | 4 | o |
합 | 7 | 9 | x |
불 | 9 | 2 | x |

데이터를 합/불에 따라서 나눈 후에 각 class에서 서류 점수, 면접 점수의 평균과 표준편차 그리고 석사 여부의 범주별 확률을 계산합니다.

|   class    |   서류 점수(평균,분산)    | 면접 점수(평균,분산)  | 석사 여부(o,x) | $$P(C_{k})$$ |
| :-----:  | :-------: | :-------: | :-----: | :-----: |
| $$C_{1}$$=합  |  8.33/1.52 |  9.33/0.57  | 0.33/0.66 | 0.6 |
| $$C_{2}$$=불  | 8.5/0.707  |  3/1.41  | 0.5/0.5 | 0.4 |

조금만 계산되는 과정을 보면 합에 해당되는 데이터의 서류 점수 값이 10,8,7이므로 $$\frac{10+8+7}{3}=8.33$$으로 구해지고 세 값의 표준 편차 역시 계산할 수 있습니다. 또한 석사 여부가 x,o,x 이므로 $$\frac{1}{3}=0.33, \frac{2}{3}=0.66$$로 계산됩니다. 한편, 전체 데이터 중 합이 3개 이므로 $$\frac{3}{5}=0.6$$으로 $$P(합)$$이 계산됩니다.

### 예측 예시

새로운 데이터 (서류, 면접, 석사여부) = (10, 7, x)가 들어왔다고 합시다. 앞서 구한 값으로 우리는 이 데이터의 합불 여부를 예측하고 싶습니다. 그러려면 P(합$$\lvert$$(10,7,x)) vs P(불합$$\lvert$$(10,7,x))을 비교해야 합니다. 즉, P(서류=10$$\lvert$$합)P(면접=7$$\lvert$$합)P(석사=x$$\lvert$$합)P(합) vs P(서류=10$$\lvert$$불)P(면접=7$$\lvert$$불)P(석사=x$$\lvert$$불)P(불)를 비교하는 것이죠.

연속형 변수의 경우에는 구해 놓은 평균 분산을 가지는 정규 분포의 확률 밀도 함수에 해당 값을 대입해서 값을 구하고(이에 대해서는 확률 밀도 함수(probability density function)에 대한 이해가 필요합니다.) 범주형 변수는 구해 놓은 범주에 속할 확률을 그대로 사용합니다.

|   class    |   P(서류=10$$\lvert C_{k}$$)    | P(면접=7$$\lvert C_{k}$$)  | P(석사=x$$\lvert C_{k}$$) | $$P(C_{k})$$ |
| :-----:  | :-------: | :-------: | :-----: | :-----: |
| $$C_{1}$$=합  |  0.14 | 0.00016  | 0.66 | 0.6 |
| $$C_{2}$$=불  | 0.059  |  0.005  | 0.5 | 0.4 |

이에 따라 각 행을 다 곱해서 값을 구하면, P(합$$\lvert$$(10,7,x))=9.36e-06 < P(불$$\lvert$$(10,7,x))=6.014e-05 입니다. 이 데이터는 불합격으로 분류되는군요.

## 그 외 사항

### Laplace Smoothing

만약 자료가 아래와 같이 주어졌다고 한다면 문제가 하나 있습니다.

| 합불 | 서류 점수 | 면접 점수 | 석사 여부 |
| :-----: | :-----: | :-----: | :-----: |
합 | 10 | 10 | o |
합 | 8 | 9 | o |
불 | 8 | 4 | o |
합 | 7 | 9 | o |
불 | 9 | 2 | o |

(10, 7, x)라는 자료를 예측하려고 했는데, 모수 추정 과정에서 P(석사=x$$\lvert$$합)=$$\frac{0}{3}=0$$, P(석사=x$$\lvert$$불합)=$$\frac{0}{2}=0$$가 되어 버립니다. 이 말은 위에서 $$P(석사=x$$\lvert C_{k}$$)$$ 부분이 전부 0이 된다는 말이죠. 그니니까 P(합$$\lvert$$(10,7,x)) = P(불합$$\lvert$$(10,7,x)) = 0이 되어버립니다. 구분을 못하게 되어 버리는 거죠. 이렇게 둘 다 0이 되는 것을 막기위해 분모, 분자에 적당한 값($$\alpha$$)을 더해 줍니다.

>$$P(x|C_{k})=\frac{m}{n}=\frac{m+\alpha}{n+\alpha \times nlevels}$$

예를 들어 $$\alpha=1$$이라면 앞선 예시에서 석사 변수는 범주(nlevels)가 2개이므로 아래와 같이 값을 바꿉니다. 그러면 둘 다 0이 되는 것을 막을 수 있죠.

P(석사=x$$\lvert$$합)=$$\frac{0+1}{3+1 \times 2}=\frac{1}{5}$$, P(석사=o$$\lvert$$합)=$$\frac{3+1}{3+1 \times 2}=\frac{4}{5}$$ \\
P(석사=x$$\lvert$$불합)=$$\frac{0+1}{2+1 \times 2}=\frac{1}{4}$$, P(석사=o$$\lvert$$불합)=$$\frac{2+1}{2+1 \times 2}=\frac{3}{4}$$

### Logarithm

확률값은 1보다 작은 수인데, 이를 연속해서 곱해 준다면 컴퓨터 연산 과정에서 0이 되어버릴 수 있습니다. 그래서 곱하기 보다 로그를 취해서 더해주는 방법이 있습니다.

> $$\log(P(x_{1}|C_{k}) \cdots P(x_{p}|C_{k})P(C_{k}))=\log(P(x_{1}|C_{k})) + \cdots + \log(P(x_{p}|C_{k})) + \log(P(C_{k}))$$

### Kernel Density Estimation

사실 연속형 변수가 정규 분포를 따른다는 가정은 상당히 어색합니다. 그래서 NBC에서는 정규 분포를 가정하기 보다는 비모수적으로 연속형 변수의 분포를 추정하기도 하는 데, 이러한 방법을 Kernel Density Estimation(KDE)이라고 합니다. 아래 그림에서 빨간 선이 KDE로 분포를 추정한 방법이고 나머지 선들은 정규 분포를 가정하고 분포를 추정한 것입니다.

<a href="https://imgur.com/RAFPeNP"><img src="https://i.imgur.com/RAFPeNP.png" width="600px" height="400px" title="source: imgur.com" /></a>
