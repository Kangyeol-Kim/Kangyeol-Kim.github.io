---
title: PageRank Algorithm을 이용한 네이버 웹툰 랭킹
category: Network
tag: Network
---

이번 글에서는 세계적인 회사인 구글을 만든 알고리즘이라고 해도 과언이 아닌 PageRank 알고리즘에 대해서 다루고 이를 활용해서 네이버 웹툰 자료로 Network를 만든 후에 웹툰 순위를 한 번 매겨보겠습니다. 세르게이 브린과 래리 페이지가 쓴 논문(The Anatomy of a Large-Scale Hypertextual Web Search Engine)에서 나온 PageRank 알고리즘은 당시 인터넷이 발전하고 있는 상황에서 사용자의 검색어에 대한 웹 페이지 제시 문제를 해결하기 위해서 제안된 알고리즘 입니다. 그 전에 쓰였던 모델은 TF-IDF를 활용해서 주어진 텍스트에 유사한(즉, TF-IDF값이 높은) 문서를 반환해 주는 것이였는데, 이는 두 가지 정도의 문제를 가졌습니다:

1. 주어진 검색어가 사용자의 Need를 잘 대변해주지 않는 경우
2. 자신들의 페이지의 순위를 높히기 위해서 웹상에 사람들이 검색어로 많이 쓰는 단어를 넣어 놓는 경우.

1의 경우는 정보 검색 이론에서 많이 제기되는 문제이고, 2의 경우는 TF-IDF가 겹치는 단어의 등장에 가중치를 준다는 사실을 이용했습니다. 2 문제를 해소하기 위해 제시된 PageRank 알고리즘(이하 PR)은 웹 문서들을 graph적 구조로 만들고 이들 사이의 관계를 통해 네트워크 내에서 중요한 노드(웹 문서)들을 뽑아내고자 하였습니다. 만약 **웹 문서들을 node 집합이라고 하고 웹 문서들 사이의 링크를 directed edge** 라고 정의하여 directed graph를 구성할 수 있다면, 결국 PR이 하고자 하는 것은 **directed graph의 node들을 정렬(sorting)하는 것** 입니다. 이에 관련된 이론은 transitive matrix의 convergence 입니다. 그리고 이 글에서는 기본적으로 directed graph와 adjacency matrix의 개념은 이미 알고 있다고 생각하고 쓰겠습니다.

## 이론적 배경

### Transitive matrix

$$n$$개의 상태가 있다고 할 때 시점이 $$t_{1}$$에서 $$t_{2}$$와 같이 변할 때, 상태의 변화 확률을 정의합니다. 즉, transitive matrix를 $$P$$라고 한다면, $$p_{ij}=p(t_{2}=j \lvert t_{1}=i)$$라고 정의 됩니다. P의 $$(i,j)$$는 상태가 $$i$$에서 $$j$$로 바뀔 때의 확률값을 의미합니다. 쉽게 우리는 $$\sum_{j=1}^{n} p_{ij}=1$$임을 알 수 있습니다. 한 상태에서 다른 상태(자신 포함)로 변할 수 밖에 없기 때문입니다. 일반적으로 $$P$$가 **regular** 하다면 **$$\pi$$ 라는 stationery distribution을 가집니다.** regular하다는 의미는:

> **(DEFINITION)** A transition matrix P is said to be **regular** if all entries of some power of P are positive

라는 뜻으로 어느 정도 $$P$$를 계속 곱해가면 어떤 상태에서라도 모든 다른 상태로 갈 수 있는 확률이 존재한다는 의미입니다. 한편, $$\pi$$는 임의의 초기값 $$\alpha$$에 대해서 아래와 같이 정의 됩니다.

> $$ \pi = \lim_{n\to\infty} \alpha P^{n} = \lim_{n\to\infty} \alpha (P^{n-1} P) = (\lim_{n\to\infty} \alpha P^{n-1}) P = \pi P   $$

이 때의 $$\pi$$를 stationery distribution이라고 부릅니다. P를 무한번 곱할 때 $$\pi$$로 convergence하는 것이죠. 이는 결국 최종적으로 각 상태에 머무르는 확률을 구하는 것입니다.

### Directed graph와 Transitive matrix와의 연결성

사실 transitive matrix는 아래와 같이 weighted directed graph라고 할 수 있습니다. 여기서 weight는 확률입니다.

<center><a href="https://imgur.com/os8Pg4R"><img src="https://i.imgur.com/os8Pg4R.png" width="400px" height="250px" title="source: imgur.com" /></a></center>

기본적으로 PR은 이와 같은 사실을 이용합니다. 구체적으로 PR은 아래와 같은 방법을 과정을 거칩니다.

1. (web pages, links) = (nodes, edges)로 directed graph를 만듭니다.
2. 해당 directed graph의 adjacency matrix 를 잘 변형해서 transitive matrix를 만듭니다.
3. transition matrix를 regular 하게 만듭니다.
4. 이에 대해 stationery distribution을 찾고 이는 유저가 각 웹 문서에 최종적으로 머무르게 되는 확률이라고 할 수 있습니다. 이를 통해 노드들을 정렬합니다.

## PageRank 설명

### Intuition

PR에서는 아래와 같이 노드의 점수를 매기고 싶어 합니다.

<center><a href="https://imgur.com/nqDHdY5"><img src="https://i.imgur.com/nqDHdY5.png" width="600px" height="400px" title="source: imgur.com" /></a></center>

이는 다음을 의미하죠

* 많은 in-link를 받을 수록 노드 점수가 높다.
* 노드 점수와 out-link의 수에 따라 link에 가중치를 부여합니다.
* 웹 사이의 link가 없더라도 다른 웹으로 이동할 수 있다. (Random Surfer Problem)

### 2-3 과정에 대한 구체적 설명

directed graph의 adjacency matrix를 $$A_{(n \times n)}$$, $$M_{(n \times n)}$$를 $$m_{ii}=\sum_{j=1}^{n} A_{ij}$$인 대각행렬이라고 합시다. 즉, $$M$$의 $$k$$번째 대각 성분은 $$A$$의 $$k$$번째 행의 합(out-link의 합)입니다. 그러면 일단 정의상 $$P=LM^{-1}$$은 transition matrix입니다. 하지만 아직 (1) **regular 하다는 보장** 이 없습니다. 웹 페이지는 많고 link는 그에 비해 적으므로 adjacency matrix은 sparse 할 것이고, 그러면 P 역시 sparse 할 것 입니다. 그러면 regular 하지 않을 가능성이 높습니다. (2) 그리고 웹에서는 link가 없다고 그 페이지로 이동하지 못하는 것은 아닙니다. 그래서 한 웹에서 link로 연결되지 않은 다른 웹으로 갈 수 있다는 경우 역시 생각해야 됩니다.**(Random Surfer Problem)**

(1), (2)를 해소하기 위해서 transition matrix임을 유지하면서 0 성분에 적당한 값들을 더해 줍니다. $$P^{'}=\frac{1-d}{n}E_{(n \times n)} + dLM^{-1}$$. 여기서 $$E$$는 모든 성분이 1인 행렬, $$d$$는 damping factor라고 부르며 구글 검색 엔진에서는 이 값을 0.85정도로 하고 있다고 알려져 있습니다. 정리하면 $$P^{'}$$는 아래와 같은 값을 가집니다.

$$
\begin{equation}
  P^{'}_{ij}=\left\{
    \begin{array}{@{} l c @{}}
      \frac{1-d}{n}+\frac{d}{m_{ii}} & \text{edge exists} \\
      \frac{1-d}{n} & \text{otherwise}
    \end{array}\right.
  \label{eq4}
\end{equation}
$$

위에 정의에 따르면 일단 edge가 있는 성분에는 $$d \times \frac{1}{\#(out-link 수)}$$만큼 값을 주고, 나머지 $$(1-d)$$를 모든 성분에 나누어서 $$\frac{1-d}{n}$$만큼 주는 것입니다. 이렇게 transition matrix를 정의한다면 모든 성분이 >0 이 되고 regular 조건을 충족하게 됩니다. 또 Random Surfer도 고려해 주게 됩니다. 정의된 regular transition matrix를 통해 stationery distribution을 구할 수 있고, 이를 통해 각 node의 확률값을 계산하고 sorting 할 수 있습니다.

## Application-네이버 웹툰 네트워크

### 네트워크 만들기
네이버 웹툰은 보통 일주일 단위로 연재되는 짧은 만화로, 무비용으로 볼 수 있다는 점과 그 재미 때문에 네이버의 콘텐츠 중 가장 성공한 콘텐츠로 평가받습니다. 네이버에서는 한 웹툰을 본 독자들이 많이 본 다른 웹툰(1-5위 혹은 5개보다 적을 수 있음)을 추천하는 **이 만화 독자들이 많이 본 만화** 서비스를 제공합니다. 아래는 수요연재 웹툰 '연놈'의 예시입니다.

<center><a href="https://imgur.com/jgwd0WR"><img src="https://i.imgur.com/jgwd0WR.png" width="300px" height="200px" title="source: imgur.com" /></a></center>

개인적인 의견으로는 네트워크를 구성하는 것은 생성자가 어떻게 (node, edge) 집합을 정의하느냐가 중요하다고 생각합니다. 이는 생성자가 네트워크를 어떻게 정의하느냐에 따라 다양한 네트워크를 만들 수 있다는 이야기입니다. 여기서 (node, edge) = (웹툰, 이 만화 독자들이 많이 본 만화)로 정의한다면 네이버 웹툰 네트워크를 만들 수 있습니다. 이러한 아이디어는 익룡이야(kirokkk123)님의 블로그를 참조했음을 알립니다.(<a src="http://blog.naver.com/PostView.nhn?blogId=kirokkk123&logNo=90194636915">해당 포스트</a>) 위와 같은 방법으로 네이버 웹툰 네트워크를 구성한다면 아래와 같은 네트워크를 얻을 수 있습니다. (17년 6월 기준)

<ceter><a href="https://imgur.com/rHcW9b2"><img src="https://i.imgur.com/rHcW9b2.png" width="600px" height="400px" title="source: imgur.com" /></a></ceter>

node의 크기는 in-link 개수로 하였습니다. 줌인해 볼 수 있습니다.

<center><a href="https://imgur.com/BDI2C6D"><img src="https://i.imgur.com/BDI2C6D.png" width="600px" height="400px" title="source: imgur.com" /></a></center>

### 웹툰 순위 매기기

PR를 통해 해당 네트워크 node들의 순위를 매길 수 있습니다. 제 네트워크의 경우 503개의 node와 1800여개의 edge로 구성되었습니다.

```r
###########PageRank algorithm##############
dat <- read.csv("network_for_pic.csv", sep= ",", fileEncoding = "euc-kr", header = FALSE)
datm <- as.matrix(dat)
title_list <- as.vector(read.csv("webtoon_title.csv", header = FALSE))[-504]

library(igraph)

net_graph <- graph.data.frame(d = dat, directed = TRUE)
net_graph <- delete_vertices(net_graph, 504)

# PR implementation
point <- page.rank(net_graph)$vector
res <- data.frame(title_list, point)
row.names(res) <- 1:503

# sorting
orders <- order(point, decreasing = TRUE)
res <- as.data.frame(res[orders,])
res
```

| title_list | point |
| 마음의 소리 |0.0106 |
|언덕 위의 제임스 | 0.0099 |
|203호 저승사자 |0.0096 |
|갓 오브 하이스쿨 | 0.0092 |
| 갸오오와 사랑꾼들 | 0.0090 |
|오! 주예수여 | 0.0087 |

분석 결과 마음의 소리, 언덕 위의 제임스, 203호 저승사자 순으로 네트워크 내에서 중요하다고 판단할 수 있습니다.
